"""
TaskWeaver AI ç»Ÿä¸€LLMå®¢æˆ·ç«¯

æ”¯æŒå¤šç§LLMæä¾›å•†ï¼ŒåŒ…æ‹¬ç¡…åŸºæµåŠ¨ã€OpenAIç­‰
"""

import os
import json
from typing import Dict, List, Optional, Any
from enum import Enum

# è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
def load_env():
    """åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
    env_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
    if os.path.exists(env_file):
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"').strip("'")
                        if not os.getenv(key):  # åªè®¾ç½®æœªè®¾ç½®çš„å˜é‡
                            os.environ[key] = value
        except Exception:
            pass  # é™é»˜å¤±è´¥

# åŠ è½½ç¯å¢ƒå˜é‡
load_env()


class LLMProvider(Enum):
    """LLMæä¾›å•†æšä¸¾"""
    SILICONFLOW = "siliconflow"
    OPENAI = "openai"


class LLMClient:
    """
    ç»Ÿä¸€LLMå®¢æˆ·ç«¯
    
    è‡ªåŠ¨æ ¹æ®é…ç½®é€‰æ‹©æœ€ä½³å¯ç”¨çš„LLMæä¾›å•†
    """
    
    def __init__(self, provider: str = None, api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            provider: LLMæä¾›å•† ('siliconflow' æˆ– 'openai')ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            api_key: APIå¯†é’¥ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.provider = provider or os.getenv('DEFAULT_LLM_PROVIDER', 'siliconflow')
        self.client = None
        self.model = model
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self._init_client(api_key)
    
    def _init_client(self, api_key: str = None):
        """åˆå§‹åŒ–å…·ä½“çš„å®¢æˆ·ç«¯"""
        if self.provider == LLMProvider.SILICONFLOW.value:
            self._init_siliconflow_client(api_key)
        elif self.provider == LLMProvider.OPENAI.value:
            self._init_openai_client(api_key)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {self.provider}")
    
    def _init_siliconflow_client(self, api_key: str = None):
        """åˆå§‹åŒ–ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯"""
        try:
            import openai
            
            # ä½¿ç”¨APIå¯†é’¥
            api_key = api_key or os.getenv('SILICONFLOW_API_KEY')
            if not api_key:
                raise ValueError("ç¼ºå°‘ç¡…åŸºæµåŠ¨APIå¯†é’¥")
            
            # è®¾ç½®é»˜è®¤æ¨¡å‹
            if not self.model:
                self.model = os.getenv('SILICONFLOW_MODEL', 'Qwen/Qwen2.5-72B-Instruct')
            
            # åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨çš„APIç«¯ç‚¹
            self.client = openai.OpenAI(
                api_key=api_key,
                base_url=os.getenv('SILICONFLOW_BASE_URL', 'https://api.siliconflow.cn/v1')
            )
            
            print(f"âœ… ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")
            
        except ImportError:
            print("âŒ æœªå®‰è£…openaiåº“ï¼Œæ— æ³•ä½¿ç”¨ç¡…åŸºæµåŠ¨API")
            self.client = None
        except Exception as e:
            print(f"âŒ ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    def _init_openai_client(self, api_key: str = None):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            import openai
            
            # ä½¿ç”¨APIå¯†é’¥
            api_key = api_key or os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise ValueError("ç¼ºå°‘OpenAI APIå¯†é’¥")
            
            # è®¾ç½®é»˜è®¤æ¨¡å‹
            if not self.model:
                self.model = os.getenv('OPENAI_MODEL', 'gpt-4')
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = openai.OpenAI(api_key=api_key)
            
            print(f"âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")
            
        except ImportError:
            print("âŒ æœªå®‰è£…openaiåº“ï¼Œæ— æ³•ä½¿ç”¨OpenAI API")
            self.client = None
        except Exception as e:
            print(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    def chat_completion(self, messages: List[Dict[str, str]], 
                       temperature: float = 0.1, 
                       max_tokens: int = 2000) -> Optional[str]:
        """
        èŠå¤©å®ŒæˆAPIè°ƒç”¨
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "system/user/assistant", "content": "å†…å®¹"}]
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            AIå›å¤å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.client:
            print("âŒ LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def simple_completion(self, prompt: str, 
                         system_prompt: str = None,
                         temperature: float = 0.1, 
                         max_tokens: int = 2000) -> Optional[str]:
        """
        ç®€å•å®ŒæˆAPIè°ƒç”¨
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            system_prompt: ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            AIå›å¤å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        messages = []
        
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        messages.append({"role": "user", "content": prompt})
        
        return self.chat_completion(messages, temperature, max_tokens)
    
    def get_provider_info(self) -> Dict[str, Any]:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        return {
            "provider": self.provider,
            "model": self.model,
            "available": self.is_available(),
            "api_base": getattr(self.client, 'base_url', None) if self.client else None
        }


# ä¾¿æ·å‡½æ•°
def create_llm_client(provider: str = None, api_key: str = None, model: str = None) -> LLMClient:
    """åˆ›å»ºLLMå®¢æˆ·ç«¯çš„ä¾¿æ·å‡½æ•°"""
    return LLMClient(provider, api_key, model)


def get_available_providers() -> List[str]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†"""
    providers = []
    
    # æ£€æŸ¥ç¡…åŸºæµåŠ¨
    if os.getenv('SILICONFLOW_API_KEY'):
        providers.append(LLMProvider.SILICONFLOW.value)
    
    # æ£€æŸ¥OpenAI
    if os.getenv('OPENAI_API_KEY'):
        providers.append(LLMProvider.OPENAI.value)
    
    return providers


def auto_select_provider() -> str:
    """è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¯ç”¨çš„LLMæä¾›å•†"""
    available = get_available_providers()
    
    if not available:
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„LLMæä¾›å•†ï¼Œè¯·é…ç½®APIå¯†é’¥")
    
    # ä¼˜å…ˆé€‰æ‹©ç¡…åŸºæµåŠ¨
    if LLMProvider.SILICONFLOW.value in available:
        return LLMProvider.SILICONFLOW.value
    
    # å¤‡é€‰OpenAI
    if LLMProvider.OPENAI.value in available:
        return LLMProvider.OPENAI.value
    
    return available[0]


if __name__ == "__main__":
    """æµ‹è¯•LLMå®¢æˆ·ç«¯"""
    print("ğŸ¤– æµ‹è¯•LLMå®¢æˆ·ç«¯...")
    
    try:
        # è‡ªåŠ¨é€‰æ‹©æä¾›å•†
        provider = auto_select_provider()
        print(f"è‡ªåŠ¨é€‰æ‹©æä¾›å•†: {provider}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_llm_client(provider)
        
        if client.is_available():
            print("å®¢æˆ·ç«¯å¯ç”¨ï¼Œè¿›è¡Œæµ‹è¯•...")
            
            response = client.simple_completion(
                "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚",
                "ä½ æ˜¯TaskWeaver AIé¡¹ç›®è§„åˆ’åŠ©æ‰‹ã€‚"
            )
            
            if response:
                print(f"âœ… æµ‹è¯•æˆåŠŸ: {response[:100]}...")
            else:
                print("âŒ æµ‹è¯•å¤±è´¥")
        else:
            print("âŒ å®¢æˆ·ç«¯ä¸å¯ç”¨")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
